{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who is Exposed to Coastal Hazards in Puerto Rico?\n",
    "\n",
    "### Contributors:\n",
    "- Deborah Balk \n",
    "- Kytt MacManus\n",
    "- Hieu Tran\n",
    "- Camilla Greene\n",
    "- Shemontee Chowdhury\n",
    "\n",
    "### Language:\n",
    "- Python/Jupyter Book\n",
    "\n",
    "### Datasets:\n",
    "- GHS-Built\n",
    "- LECZ\n",
    "- NHGIS\n",
    "- LiDAR SAR\n",
    "\n",
    "### Areas of Interest (AOIs):\n",
    "- Puerto Rico (PRI)\n",
    "\n",
    "### Functions:\n",
    "- Image segmentation\n",
    "- Validation with SAR or LiDAR\n",
    "\n",
    "# Overview\n",
    "\n",
    "In this lesson, you will use the dataset delineating [Low Elevation Coastal Zones](https://sedac.ciesin.columbia.edu/data/set/lecz-low-elevation-coastal-zones) from the NASA Socioeconomic Data and Applications Center (SEDAC) website along with census data from the [US Census Bureau](https://www.census.gov/data.html). \n",
    "\n",
    "You will perform various preprocessing tasks to prepare the raw spatial data for analysis. These steps include exploring the dataset with visualizations and thematic mapping tools. You will then learn how to generate summary statistics based on combinations of these two layers, over two different time periods. \n",
    "\n",
    "You will learn how to perform numerous data manipulations, create statistical summaries of population-at-risk (and related housing characteristics), and examine a decade of change throughout this lesson.\n",
    "\n",
    "# Learning Objectives\n",
    "\n",
    "- Become familiar with Low Elevation Coastal Zones (LECZs) and explain their significance (as well as limitations) in assessing coastal hazard exposure.\n",
    "- Access, integrate, explore, and use LECZ data from NASA SEDAC and demographic data from the US Census Bureau for Puerto Rico.\n",
    "- Assess decadal changes (2010â€“2020) in population and housing characteristics in coastal versus non-coastal zones in Puerto Rico.\n",
    "- Create regional and local scale maps and statistical figures of exposure and decadal change.\n",
    "- Identify venues for sharing output (for example, discussion board associated with data, policy briefs, op-eds).\n",
    "\n",
    "# Introduction\n",
    "\n",
    "Low Elevation Coastal Zones (LECZs) have been defined globally, with population estimates for areas below 5m and 10m elevations (McGranahan et al. 2007, MacManus et al. 2021). In the continental U.S. (CONUS), 1 in 10 people live in the 10m LECZ, and studies highlight that urban residents, people of color, and older adults are disproportionately exposed. For instance, about 1 in 5 urban Black residents live in this zone (Tagtachian and Balk 2023, Hauer et al. 2020).\n",
    "\n",
    "However, many studies focus exclusively on CONUS, excluding U.S. territories like Puerto Rico, Alaska, and Hawaii, even though they share similar statistical infrastructure and have considerable coastal exposure due to their long coastlines and low elevations.\n",
    "\n",
    "The omission of territories often stems from limitations in data or computational resources. Some U.S. territories, such as Guam and the U.S. Virgin Islands, lack detailed housing data, and the American Community Survey is not conducted there. Satellite data, such as from SRTM, may also have lower accuracy in polar regions. Additionally, different map projections in territories pose computational challenges when processing spatial data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipumspy import readers, ddi, IpumsApiClient, AggregateDataExtract, Dataset, DatasetMetadata\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import os\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import arcgis\n",
    "from arcgis.gis import GIS\n",
    "from arcgis.map import Map\n",
    "from arcgis.raster import Raster\n",
    "from arcgis.features import GeoAccessor\n",
    "from arcgis.map.renderers import (\n",
    "    ClassBreaksRenderer,\n",
    "    ClassBreakInfo,\n",
    "    UniqueValueRenderer,\n",
    "    UniqueValueInfo,\n",
    "    SizeInfoVisualVariable,\n",
    ")\n",
    "\n",
    "from arcgis.map.symbols import SimpleLineSymbolEsriSLS, SimpleFillSymbolEsriSFS\n",
    "\n",
    "import geopandas as gpd\n",
    "import glob\n",
    "from zipfile import ZipFile\n",
    "import earthaccess as ea\n",
    "import requests\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the arcgis version for mapping properly \n",
    "\n",
    "arcgis.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using IPUMS API to pull U.S Census Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the IPUMS API key from the .env file\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "IPUMS_API_KEY = os.getenv(\"IPUMS_API_KEY\")\n",
    "ipums = IpumsApiClient(IPUMS_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run when you do not have data downloaded to your local drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting shapefile metadata in order to get the filename for downloading the shapefile in the above chunk\n",
    "\n",
    "for page in ipums.get_metadata_catalog(\"nhgis\", metadata_type=\"shapefiles\"):\n",
    "    for shapefile in page[\"data\"]:\n",
    "        if shapefile[\"extent\"] == \"Puerto Rico\":\n",
    "            if shapefile[\"geographicLevel\"] == \"Block Group\" and shapefile[\"year\"] == \"2010\":\n",
    "                print( \"Name: \" + shapefile[\"name\"] + \" | Year: \" + shapefile[\"year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submit extraction data to IPUMS portal\n",
    "\n",
    "extract = AggregateDataExtract(\n",
    "    collection=\"nhgis\",\n",
    "    description=\"Puerto Rico 2010-2020 vacancy\",\n",
    "    # datasets=[\n",
    "    #     Dataset(name=\"2010_SF1a\", data_tables=[\"H1\", \"H3\"], geog_levels=[\"blck_grp\"]),\n",
    "    #     Dataset(name = \"2020_DHCa\", data_tables = [\"H1\", \"H3\"], geog_levels = [\"blck_grp\"]),\n",
    "    # ],\n",
    "    # geographic_extents=[\"720\"],\n",
    "    shapefiles=[\"720_blck_grp_2020_tl2020\"] #Get the shapefile name from below chunk\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submit the extract request\n",
    "ipums.submit_extract(extract)\n",
    "print(f\"Extract ID: {extract.extract_id}\")\n",
    "\n",
    "#Wait for the extract to finish\n",
    "ipums.wait_for_extract(extract)\n",
    "\n",
    "#Download the extract\n",
    "current = os.getcwd()\n",
    "DOWNLOAD_DIR = os.path.join(f\"{current}/data/county_data\")\n",
    "ipums.download_extract(extract, download_dir=DOWNLOAD_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "current = os.getcwd()\n",
    "DOWNLOAD_DIR = os.path.join(f\"{current}/data/county_data\")\n",
    "\n",
    "file_list = os.listdir(DOWNLOAD_DIR)\n",
    "csv_zip = [f for f in file_list if f.endswith('_csv.zip')]\n",
    "shape_zip = [f for f in file_list if f.endswith('_shape.zip')]\n",
    "csv = f\"{DOWNLOAD_DIR}/{csv_zip[0]}\" \n",
    "shapefile = f\"{DOWNLOAD_DIR}/{shape_zip[0]}\"\n",
    "csv_data = ZipFile(csv).namelist()\n",
    "shape_data = ZipFile(shapefile).namelist()\n",
    "\n",
    "# Read zip data file in the extract\n",
    "with ZipFile(shapefile) as outer_zip: # Shapefile data has 2 zipped layers\n",
    "    with outer_zip.open(shape_data[0]) as inner_zip:\n",
    "        with ZipFile(inner_zip) as inner:\n",
    "            inner.extractall(DOWNLOAD_DIR) #Extract the shapefile into the data folder\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run from here if you already downloaded the data from the above chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "current = os.getcwd()\n",
    "DOWNLOAD_DIR = os.path.join(f\"{current}/data/county_data\")\n",
    "\n",
    "file_list = os.listdir(DOWNLOAD_DIR)\n",
    "csv_zip = [f for f in file_list if f.endswith('_csv.zip')]\n",
    "shape_zip = [f for f in file_list if f.endswith('_shape.zip')]\n",
    "csv = f\"{DOWNLOAD_DIR}/{csv_zip[0]}\" \n",
    "shapefile = f\"{DOWNLOAD_DIR}/{shape_zip[0]}\"\n",
    "csv_data = ZipFile(csv).namelist()\n",
    "shape_data = ZipFile(shapefile).namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what is inside the zip\n",
    "print(csv_data)\n",
    "print(shape_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read csv data\n",
    "\n",
    "with ZipFile(csv) as z:\n",
    "    with z.open(csv_data[0]) as f: \n",
    "        df_2020 = pd.read_csv(f)\n",
    "    with z.open(csv_data[1]) as f:\n",
    "        df_2010 = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_shp = pd.DataFrame.spatial.from_featureclass(location = \"./data/county_data/US_county_2020.shp\", sr = 3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = Map(\"Puerto Rico\")\n",
    "m1.content.add(county_shp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used Earthdata to download NASA published dataset to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Login to the Earthdata\n",
    "# # Create a username and password in .env file where you stored IPUMS API key\n",
    "# auth = ea.login(strategy= \"environment\")\n",
    "\n",
    "## Using earthaccess to search and find \n",
    "\n",
    "# url = \"https://cmr.earthdata.nasa.gov/search/collections?concept_id[]=C123456-LPDAAC_ECS\"\n",
    "\n",
    "# query = ea.search_datasets(keyword = \"LECZ\")\n",
    "# for collection in query[:10]:\n",
    "#     pprint.pprint(collection.summary(), sort_dicts=True, indent=4)\n",
    "#     print('')  # Add a space between collections for readability\n",
    "\n",
    "# #Download the data through the Earthdata\n",
    "# Query = (\n",
    "#     ea.granule_query()\n",
    "#     .short_name(\"CIESIN_SEDAC_LECZ_URPLAEV3\")\n",
    "#     .debug(True)\n",
    "# )\n",
    "\n",
    "# print(f\"Granule hits: {Query.hits()}\")\n",
    "\n",
    "# # Get the first 10 granules\n",
    "# granules = Query.get(10)\n",
    "\n",
    "# #Check if the granules are cloud hosted\n",
    "# granules[1].cloud_hosted\n",
    "# download_file = ea.download(granules[1], local_path=\"./data\")\n",
    "\n",
    "#Load data to the notebook\n",
    "\n",
    "# tiff = [f for f in file_list if f.endswith('-geotiff.zip')]\n",
    "\n",
    "# tiff_path = os.path.join(f\"{DOWNLOAD_DIR}/{tiff[0]}\")\n",
    "\n",
    "\n",
    "# with ZipFile(tiff_path) as z:\n",
    "#     z.extractall(DOWNLOAD_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2010.shape, df_2020.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2020.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To map the shapefile to the map, we have to publish the shapefile as feature layer on MapViewer on ArcGIS Online by adding layer from your shapefile zipped folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename the columns the human readable names\n",
    "\n",
    "\n",
    "# Get the layer from the published data\n",
    "\n",
    "gis = GIS()\n",
    "layer = gis.content.get(\"340a1b447c99404a820f53fd989c1839\").layers[0] # The layer of PR county 2020 published to the portal\n",
    "\n",
    "\n",
    "sedf = layer.query(where = \"STATEFP = '72'\").sdf # Query the layer to get only the PR data\n",
    "\n",
    "\n",
    "# The NHGIS codes are as follows in the documentation which is downloaded from the IPUMS API \n",
    "\n",
    "# Rename columns for dataframe 2020\n",
    "\n",
    "'''    Table 1:     Housing Units\n",
    "    Universe:    Housing units\n",
    "    Source code: H1\n",
    "    NHGIS code:  U9V\n",
    "        U9V001:      Total\n",
    " \n",
    "    Table 2:     Occupancy Status\n",
    "    Universe:    Housing units\n",
    "    Source code: H3\n",
    "    NHGIS code:  U9X\n",
    "        U9X001:      Total\n",
    "        U9X002:      Occupied\n",
    "        U9X003:      Vacant\n",
    "'''\n",
    "rename_2020 = {\n",
    "    \"U9V001\": \"Total_Housing\",\n",
    "    \"U9X001\": \"Total_Housing_Units\",\n",
    "    \"U9X002\": \"Occupied\",\n",
    "    \"U9X003\": \"Vacant\"\n",
    "}\n",
    "\n",
    "#Rename columns for dataframe 2010\n",
    "'''    Table 1:     Housing Units\n",
    "    Universe:    Housing units\n",
    "    Source code: H1\n",
    "    NHGIS code:  IFC\n",
    "        IFC001:      Total\n",
    " \n",
    "    Table 2:     Occupancy Status\n",
    "    Universe:    Housing units\n",
    "    Source code: H3\n",
    "    NHGIS code:  IFE\n",
    "        IFE001:      Total\n",
    "        IFE002:      Occupied\n",
    "        IFE003:      Vacant'''\n",
    "\n",
    "rename_2010 = {\n",
    "    \"IFC001\": \"Total_Housing\",\n",
    "    \"IFE001\": \"Total_Housing_Units\",\n",
    "    \"IFE002\": \"Occupied\",\n",
    "    \"IFE003\": \"Vacant\"\n",
    "}\n",
    "\n",
    "df_2010.rename(columns = rename_2010, inplace = True)\n",
    "df_2020.rename(columns = rename_2020, inplace = True)\n",
    "\n",
    "#Merge 2010 df to 2020 df\n",
    "test = df_2020.copy()\n",
    "\n",
    "merged_df = test.merge(df_2010[[\"GISJOIN\", \"Total_Housing\", \"Total_Housing_Units\", \"Occupied\", \"Vacant\"]], on = \"GISJOIN\", how = \"inner\", suffixes=(\"_2020\", \"_2010\"))\n",
    "\n",
    "#Merge the feature to the merged 2010-2020 df\n",
    "pr_sedf = sedf.merge(merged_df[[\"GISJOIN\", \"Total_Housing_2020\", \"Total_Housing_Units_2020\", \"Occupied_2020\", \"Vacant_2020\", \"Total_Housing_2010\", \"Total_Housing_Units_2010\", \"Occupied_2010\", \"Vacant_2010\"]], on = \"GISJOIN\", how = \"inner\")\n",
    "pr_sedf[\"Total_Vacant_Change\"] = pr_sedf[\"Vacant_2020\"] - pr_sedf[\"Vacant_2010\"]\n",
    "pr_sedf[\"Total_Vacant_Percentile\"] = pd.qcut(pr_sedf[\"Total_Vacant_Change\"], 5, labels = range(1,6)) \n",
    "\n",
    "# Create std mean for the data\n",
    "mean = pr_sedf[\"Total_Vacant_Change\"].mean()\n",
    "std = pr_sedf[\"Total_Vacant_Change\"].std()\n",
    "\n",
    "\n",
    "# Create a function to classify the data into standard deviations\n",
    "def classify_std(value, mean, std):\n",
    "    if value < mean - 2*std:\n",
    "        return \"< -2 Std Dev\"\n",
    "    elif mean - 2*std <= value < mean - std:\n",
    "        return \"-2 to -1 Std Dev\"\n",
    "    elif mean - std <= value < mean:\n",
    "        return \"-1 to 0 Std Dev\"\n",
    "    elif mean <= value < mean + std:\n",
    "        return \"0 to 1 Std Dev\"\n",
    "    elif mean + std <= value < mean + 2*std:\n",
    "        return \"1 to 2 Std Dev\"\n",
    "    elif mean + 2*std <= value:\n",
    "        return \"> 2 Std Dev\"\n",
    "\n",
    "pr_sedf[\"Total_Vacant_Change_Std\"] = pr_sedf[\"Total_Vacant_Change\"].apply(lambda x: classify_std(x, mean, std))\n",
    "\n",
    "pr_sedf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search for the LECZ layer in the ArcGIS Online\n",
    "\n",
    "lecz_layer = gis.content.search(\"Low Elevation Coastal Zones derived from MERIT-DEM\", item_type=\"Imagery Layer\")\n",
    "for item in lecz_layer:\n",
    "    display(item)\n",
    "lecz = lecz_layer[1] #Change 0 to 1 or vice versa to get the MERIT-DEM layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modify the title and the label of the LECZ layer\n",
    "\n",
    "lecz_wm = gis.content.get(\"5252dcb860724f62a1e988c4bac0e321\")\n",
    "\n",
    "\n",
    "## get the symbology definition from the original webmap\n",
    "layer_def = lecz_wm.get_data()[\"operationalLayers\"][0][\"layerDefinition\"]\n",
    "\n",
    "## update the label classes\n",
    "layer_def[\"drawingInfo\"][\"renderer\"][\"uniqueValueGroups\"][0][\"classes\"][0][\"label\"] = \"0 - 5m\"\n",
    "layer_def[\"drawingInfo\"][\"renderer\"][\"uniqueValueGroups\"][0][\"classes\"][1][\"label\"] = \"0 - 5m\"\n",
    "layer_def[\"drawingInfo\"][\"renderer\"][\"uniqueValueGroups\"][0][\"classes\"][2][\"label\"] = \"0 - 5m\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unique Value Renderer\n",
    "\n",
    "\n",
    "quantile_labels = ['Lowest 20%', '20-40%', '40-60%', '60-80%', 'Highest 20%']\n",
    "\n",
    "\n",
    "symbol1 = SimpleFillSymbolEsriSFS(\n",
    "    color = [26,150,65, 255], \n",
    "    outline = SimpleLineSymbolEsriSLS(\n",
    "        color = [153, 153, 153, 255], style = \"esriSLSSolid\", width = 0.5,\n",
    "    ),\n",
    "    style=\"esriSFSSolid\",\n",
    "    type=\"esriSFS\",\n",
    ")\n",
    "symbol2 = SimpleFillSymbolEsriSFS(\n",
    "    color = [166,217,106, 255], \n",
    "    outline = SimpleLineSymbolEsriSLS(\n",
    "        color = [153, 153, 153, 255], style = \"esriSLSSolid\", width = 0.5,\n",
    "    ),\n",
    "    style=\"esriSFSSolid\",\n",
    "    type=\"esriSFS\",\n",
    ")\n",
    "\n",
    "symbol3 = SimpleFillSymbolEsriSFS(\n",
    "    color = [255,255,191, 255], \n",
    "    outline = SimpleLineSymbolEsriSLS(\n",
    "        color = [153, 153, 153, 255], style = \"esriSLSSolid\", width = 0.5,\n",
    "    ),\n",
    "    style=\"esriSFSSolid\",\n",
    "    type=\"esriSFS\",\n",
    ")\n",
    "\n",
    "symbol4 = SimpleFillSymbolEsriSFS(\n",
    "    color = [253,174,97, 255], \n",
    "    outline = SimpleLineSymbolEsriSLS(\n",
    "        color = [153, 153, 153, 255], style = \"esriSLSSolid\", width = 0.5,\n",
    "    ),\n",
    "    style=\"esriSFSSolid\",\n",
    "    type=\"esriSFS\",\n",
    ")\n",
    "\n",
    "symbol5 = SimpleFillSymbolEsriSFS(\n",
    "    color = [215,25,28, 255], \n",
    "    outline = SimpleLineSymbolEsriSLS(\n",
    "        color = [153, 153, 153, 255], style = \"esriSLSSolid\", width = 0.5,\n",
    "    ),\n",
    "    style=\"esriSFSSolid\",\n",
    "    type=\"esriSFS\",\n",
    ")\n",
    "unique_value_infos = [\n",
    "    UniqueValueInfo(\n",
    "        value=1,\n",
    "        label=quantile_labels[0],\n",
    "        symbol=symbol1,\n",
    "    ),\n",
    "    UniqueValueInfo(\n",
    "        value=2,\n",
    "        label=quantile_labels[1],\n",
    "        symbol=symbol2,\n",
    "    ),\n",
    "    UniqueValueInfo(\n",
    "        value=3,\n",
    "        label=quantile_labels[2],\n",
    "        symbol=symbol3,\n",
    "    ),\n",
    "    UniqueValueInfo(\n",
    "        value=4,\n",
    "        label=quantile_labels[3],\n",
    "        symbol=symbol4,\n",
    "    ),\n",
    "    UniqueValueInfo(\n",
    "        value=5,\n",
    "        label=quantile_labels[4],\n",
    "        symbol=symbol5,\n",
    "    )\n",
    "]\n",
    "\n",
    "uvr = UniqueValueRenderer(\n",
    "    type=\"uniqueValue\",\n",
    "    field1=\"Total_Vacant_Percentile\",\n",
    "    uniqueValueInfos=unique_value_infos,\n",
    ")\n",
    "\n",
    "#Labeling info\n",
    "\n",
    "labeling_info = [\n",
    "      {\n",
    "        \"labelExpression\": \"[NAME]\",\n",
    "        \"labelPlacement\": \"esriServerPolygonPlacementAlwaysHorizontal\",\n",
    "        \"repeatLabel\": True,\n",
    "        \"symbol\": {\n",
    "          \"type\": \"esriTS\",\n",
    "          \"color\": [\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            255\n",
    "          ],\n",
    "          \"font\": {\n",
    "            \"family\": \"Arial\",\n",
    "            \"size\": 12\n",
    "          },\n",
    "          \"horizontalAlignment\": \"center\",\n",
    "          \"kerning\": True,\n",
    "        },\n",
    "      }\n",
    "]\n",
    "\n",
    "options_dict = {\n",
    "    \"showLabels\" : True,\n",
    "    \"layerDefinition\" : {\n",
    "        \"drawingInfo\" : {\n",
    "            \"labelingInfo\" : labeling_info,\n",
    "            \"renderer\" : uvr.dict(),\n",
    "        }\n",
    "    },\n",
    "    \"opacity\" : 0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = Map(lecz_wm)\n",
    "m1.content.add(pr_sedf, options = options_dict)\n",
    "m1.content.add(lecz_wm, options={\"opacity\": 0.5})\n",
    "\n",
    "## update the WebMap in Notebooks\n",
    "m1.content.update_layer(\n",
    "    index = 0, \n",
    "    options= {\n",
    "        \"title\": \"LECZ\",\n",
    "        \"layerDefinition\" : layer_def\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.legend.enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reclassify by Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unique Value Renderer\n",
    "\n",
    "\n",
    "labels = ['< -2Std Dev', '-2 to -1Std Dev', '-1 to 0Std Dev', '0 to 1Std Dev', '1 to 2Std Dev', '> 2Std Dev']\n",
    "\n",
    "\n",
    "symbol1 = SimpleFillSymbolEsriSFS(\n",
    "    color = [140,81,10, 255], \n",
    "    outline = SimpleLineSymbolEsriSLS(\n",
    "        color = [153, 153, 153, 255], style = \"esriSLSSolid\", width = 0.5,\n",
    "    ),\n",
    "    style=\"esriSFSSolid\",\n",
    "    type=\"esriSFS\",\n",
    ")\n",
    "symbol2 = SimpleFillSymbolEsriSFS(\n",
    "    color = [216,179,101, 255], \n",
    "    outline = SimpleLineSymbolEsriSLS(\n",
    "        color = [153, 153, 153, 255], style = \"esriSLSSolid\", width = 0.5,\n",
    "    ),\n",
    "    style=\"esriSFSSolid\",\n",
    "    type=\"esriSFS\",\n",
    ")\n",
    "\n",
    "symbol3 = SimpleFillSymbolEsriSFS(\n",
    "    color = [246,232,195, 255], \n",
    "    outline = SimpleLineSymbolEsriSLS(\n",
    "        color = [153, 153, 153, 255], style = \"esriSLSSolid\", width = 0.5,\n",
    "    ),\n",
    "    style=\"esriSFSSolid\",\n",
    "    type=\"esriSFS\",\n",
    ")\n",
    "\n",
    "symbol4 = SimpleFillSymbolEsriSFS(\n",
    "    color = [199,234,229, 255], \n",
    "    outline = SimpleLineSymbolEsriSLS(\n",
    "        color = [153, 153, 153, 255], style = \"esriSLSSolid\", width = 0.5,\n",
    "    ),\n",
    "    style=\"esriSFSSolid\",\n",
    "    type=\"esriSFS\",\n",
    ")\n",
    "\n",
    "symbol5 = SimpleFillSymbolEsriSFS(\n",
    "    color = [90,180,172, 255], \n",
    "    outline = SimpleLineSymbolEsriSLS(\n",
    "        color = [153, 153, 153, 255], style = \"esriSLSSolid\", width = 0.5,\n",
    "    ),\n",
    "    style=\"esriSFSSolid\",\n",
    "    type=\"esriSFS\",\n",
    ")\n",
    "\n",
    "symbol6 = SimpleFillSymbolEsriSFS(\n",
    "    color = [1,102,94, 255], \n",
    "    outline = SimpleLineSymbolEsriSLS(\n",
    "        color = [153, 153, 153, 255], style = \"esriSLSSolid\", width = 0.5,\n",
    "    ),\n",
    "    style=\"esriSFSSolid\",\n",
    "    type=\"esriSFS\",\n",
    ")\n",
    "unique_value_infos = [\n",
    "    UniqueValueInfo(\n",
    "        value=\"< -2 Std Dev\",\n",
    "        label=labels[0],\n",
    "        symbol=symbol1,\n",
    "    ),\n",
    "    UniqueValueInfo(\n",
    "        value=\"-2 to -1 Std Dev\",\n",
    "        label=labels[1],\n",
    "        symbol=symbol2,\n",
    "    ),\n",
    "    UniqueValueInfo(\n",
    "        value=\"-1 to 0 Std Dev\",\n",
    "        label=labels[2],\n",
    "        symbol=symbol3,\n",
    "    ),\n",
    "    UniqueValueInfo(\n",
    "        value=\"0 to 1 Std Dev\",\n",
    "        label=labels[3],\n",
    "        symbol=symbol4,\n",
    "    ),\n",
    "    UniqueValueInfo(\n",
    "        value=\"1 to 2 Std Dev\",\n",
    "        label=labels[4],\n",
    "        symbol=symbol5,\n",
    "    ),\n",
    "    UniqueValueInfo(\n",
    "        value=\"> 2 Std Dev\",\n",
    "        label=labels[5],\n",
    "        symbol=symbol6,\n",
    "    )\n",
    "]\n",
    "\n",
    "uvr = UniqueValueRenderer(\n",
    "    type=\"uniqueValue\",\n",
    "    field1=\"Total_Vacant_Change_Std\",\n",
    "    uniqueValueInfos=unique_value_infos,\n",
    ")\n",
    "\n",
    "#Labeling info\n",
    "\n",
    "labeling_info = [\n",
    "      {\n",
    "        \"labelExpression\": \"[NAME]\",\n",
    "        \"labelPlacement\": \"esriServerPolygonPlacementAlwaysHorizontal\",\n",
    "        \"repeatLabel\": True,\n",
    "        \"symbol\": {\n",
    "          \"type\": \"esriTS\",\n",
    "          \"color\": [\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            255\n",
    "          ],\n",
    "          \"font\": {\n",
    "            \"family\": \"Arial\",\n",
    "            \"size\": 12\n",
    "          },\n",
    "          \"horizontalAlignment\": \"center\",\n",
    "          \"kerning\": True,\n",
    "        },\n",
    "      }\n",
    "]\n",
    "\n",
    "options_dict = {\n",
    "    \"showLabels\" : True,\n",
    "    \"layerDefinition\" : {\n",
    "        \"drawingInfo\" : {\n",
    "            \"labelingInfo\" : labeling_info,\n",
    "            \"renderer\" : uvr.dict(),\n",
    "        },\n",
    "        \"name\" : \"Puerto Rico Vacant Housing Change\",\n",
    "    },\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = Map(lecz_wm)\n",
    "\n",
    "\n",
    "\n",
    "## update the WebMap in Notebooks\n",
    "m2.content.update_layer(\n",
    "    index = 0, \n",
    "    options= {\n",
    "        \"title\": \"LECZ\",\n",
    "        \"layerDefinition\" : layer_def\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2.legend.enabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting deeper to analyze what change in a county at block group level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading from zip file for block\n",
    "\n",
    "current = os.getcwd()\n",
    "DOWNLOAD_DIR = os.path.join(f\"{current}/data\")\n",
    "\n",
    "file_list = os.listdir(DOWNLOAD_DIR)\n",
    "csv_zip = [f for f in file_list if f.endswith('_csv.zip')]\n",
    "shape_zip = [f for f in file_list if f.endswith('_shape.zip')]\n",
    "csv = f\"{DOWNLOAD_DIR}/{csv_zip[0]}\" \n",
    "shapefile = f\"{DOWNLOAD_DIR}/{shape_zip[1]}\" #Block group shapefile\n",
    "csv_data = ZipFile(csv).namelist()\n",
    "shape_data = ZipFile(shapefile).namelist()\n",
    "\n",
    "#Read csv data\n",
    "\n",
    "with ZipFile(csv) as z:\n",
    "    with z.open(csv_data[-1]) as f: \n",
    "        blck_grp_2020 = pd.read_csv(f)\n",
    "    with z.open(csv_data[2]) as f:\n",
    "        blck_grp_2010 = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile(shapefile) as outer_zip: # Shapefile data has 2 zipped layers\n",
    "    with outer_zip.open(shape_data[0]) as inner_zip:\n",
    "        with ZipFile(inner_zip) as inner:   \n",
    "            inner.extractall(DOWNLOAD_DIR) #Extract the shapefile into the data folder\n",
    "\n",
    "shp_df = pd.DataFrame.spatial.from_featureclass(location = \"./data/PR_blck_grp_2020.shp\", sr = 3857)\n",
    "shp_df[\"COUNTYFP\"] = shp_df[\"COUNTYFP\"].str.replace(r\"^0+\", \"\", regex=True) #Remove leading zeros from the county codes\n",
    "shp_df[\"COUNTYFP\"] = shp_df[\"COUNTYFP\"].astype(int) #Convert the county codes to int\n",
    "shp_df[\"BLKGRPCE\"] = shp_df[\"BLKGRPCE\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregate the data by block group and county for 2010 and 2020\n",
    "\n",
    "blck_grp_2010.rename(columns = rename_2010, inplace = True)\n",
    "blck_grp_2020.rename(columns = rename_2020, inplace = True)\n",
    "\n",
    "#Merge the dataframes for 2010 and 2020 by block group and county\n",
    "\n",
    "blck_grp_merged = shp_df.merge(blck_grp_2020[[\"GISJOIN\", \"COUNTY\", \"Total_Housing_Units\", \"Occupied\", \"Vacant\"]], on = [\"GISJOIN\"], how = \"inner\", suffixes=(\"_2010\", \"_2020\"))\n",
    "\n",
    "# blck_grp_shp = shp_df.merge(blck_grp_merged[[\"GISJOIN\", \"COUNTY\", \"COUNTYA\", \"BLKGRPA\", \"Total_Housing_Units_2020\", \"Occupied_2020\", \"Vacant_2020\", \"Total_Housing_Units_2010\", \"Occupied_2010\", \"Vacant_2010\"]], on = \"GISJOIN\", how = \"right\")\n",
    "\n",
    "# blck_grp_merged[\"Total_Vacant_Change\"] = blck_grp_merged[\"Vacant_2020\"] - blck_grp_merged[\"Vacant_2010\"]\n",
    "\n",
    "\n",
    "# #Doing the EDA\n",
    "blck_grp_merged.isna().sum()   #Check for missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with TRACTA as the primary key and BLKGRPA as secondary keys\n",
    "tract_dict_2010 = {}\n",
    "\n",
    "\n",
    "for _, row in blck_grp_2010.iterrows():\n",
    "    tracta = row[\"TRACTA\"]\n",
    "    blkgrpa = row[\"BLKGRPA\"]\n",
    "    values = row.drop([\"TRACTA\", \"BLKGRPA\"]).to_dict()\n",
    "    \n",
    "    if tracta not in tract_dict_2010:\n",
    "        tract_dict_2010[tracta] = {}\n",
    "    \n",
    "    tract_dict_2010[tracta][blkgrpa] = values\n",
    "\n",
    "# Display the resulting dictionary\n",
    "tract_dict_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blck_grp_merged[\"Vacant_2010\"] = 0 #Create a new column for the 2010 vacant housing units\n",
    "blck_grp_merged[\"TRACTCE\"] = blck_grp_merged[\"TRACTCE\"].astype(int) \n",
    "\n",
    "for i in range(len(blck_grp_merged)):\n",
    "    if blck_grp_merged[\"TRACTCE\"][i] in tract_dict_2010:\n",
    "        tract = blck_grp_merged[\"TRACTCE\"][i]\n",
    "        if blck_grp_merged[\"BLKGRPCE\"][i] in tract_dict_2010[tract]:\n",
    "            blk_grp = blck_grp_merged[\"BLKGRPCE\"][i]\n",
    "            blck_grp_merged[\"Vacant_2010\"][i] = tract_dict_2010[tract][blk_grp][\"Vacant\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create std mean for the data\n",
    "blck_grp_merged[\"Total_Vacant_Change\"] = blck_grp_merged[\"Vacant\"] - blck_grp_merged[\"Vacant_2010\"]\n",
    "\n",
    "\n",
    "mean = blck_grp_merged[\"Total_Vacant_Change\"].mean()\n",
    "std = blck_grp_merged[\"Total_Vacant_Change\"].std()\n",
    "\n",
    "def classify_std(value, mean, std):\n",
    "    if value < mean - 2*std:\n",
    "        return \"< -2 Std Dev\"\n",
    "    elif mean - 2*std <= value < mean - std:\n",
    "        return \"-2 to -1 Std Dev\"\n",
    "    elif mean - std <= value < mean:\n",
    "        return \"-1 to 0 Std Dev\"\n",
    "    elif mean <= value < mean + std:\n",
    "        return \"0 to 1 Std Dev\"\n",
    "    elif mean + std <= value < mean + 2*std:\n",
    "        return \"1 to 2 Std Dev\"\n",
    "    elif mean + 2*std <= value:\n",
    "        return \"> 2 Std Dev\"\n",
    "\n",
    "blck_grp_merged[\"Total_Vacant_Change_Std\"] = blck_grp_merged[\"Total_Vacant_Change\"].apply(lambda x: classify_std(x, mean, std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unique Value Renderer\n",
    "\n",
    "\n",
    "labels = ['< -2Std Dev', '-2 to -1Std Dev', '-1 to 0Std Dev', '0 to 1Std Dev', '1 to 2Std Dev', '> 2Std Dev']\n",
    "\n",
    "\n",
    "symbol1 = SimpleFillSymbolEsriSFS(\n",
    "    color = [140,81,10, 255], \n",
    "    outline = SimpleLineSymbolEsriSLS(\n",
    "        color = [153, 153, 153, 255], style = \"esriSLSSolid\", width = 0.5,\n",
    "    ),\n",
    "    style=\"esriSFSSolid\",\n",
    "    type=\"esriSFS\",\n",
    ")\n",
    "symbol2 = SimpleFillSymbolEsriSFS(\n",
    "    color = [216,179,101, 255], \n",
    "    outline = SimpleLineSymbolEsriSLS(\n",
    "        color = [153, 153, 153, 255], style = \"esriSLSSolid\", width = 0.5,\n",
    "    ),\n",
    "    style=\"esriSFSSolid\",\n",
    "    type=\"esriSFS\",\n",
    ")\n",
    "\n",
    "symbol3 = SimpleFillSymbolEsriSFS(\n",
    "    color = [246,232,195, 255], \n",
    "    outline = SimpleLineSymbolEsriSLS(\n",
    "        color = [153, 153, 153, 255], style = \"esriSLSSolid\", width = 0.5,\n",
    "    ),\n",
    "    style=\"esriSFSSolid\",\n",
    "    type=\"esriSFS\",\n",
    ")\n",
    "\n",
    "symbol4 = SimpleFillSymbolEsriSFS(\n",
    "    color = [199,234,229, 255], \n",
    "    outline = SimpleLineSymbolEsriSLS(\n",
    "        color = [153, 153, 153, 255], style = \"esriSLSSolid\", width = 0.5,\n",
    "    ),\n",
    "    style=\"esriSFSSolid\",\n",
    "    type=\"esriSFS\",\n",
    ")\n",
    "\n",
    "symbol5 = SimpleFillSymbolEsriSFS(\n",
    "    color = [90,180,172, 255], \n",
    "    outline = SimpleLineSymbolEsriSLS(\n",
    "        color = [153, 153, 153, 255], style = \"esriSLSSolid\", width = 0.5,\n",
    "    ),\n",
    "    style=\"esriSFSSolid\",\n",
    "    type=\"esriSFS\",\n",
    ")\n",
    "\n",
    "symbol6 = SimpleFillSymbolEsriSFS(\n",
    "    color = [1,102,94, 255], \n",
    "    outline = SimpleLineSymbolEsriSLS(\n",
    "        color = [153, 153, 153, 255], style = \"esriSLSSolid\", width = 0.5,\n",
    "    ),\n",
    "    style=\"esriSFSSolid\",\n",
    "    type=\"esriSFS\",\n",
    ")\n",
    "unique_value_infos = [\n",
    "    UniqueValueInfo(\n",
    "        value=\"< -2 Std Dev\",\n",
    "        label=labels[0],\n",
    "        symbol=symbol1,\n",
    "    ),\n",
    "    UniqueValueInfo(\n",
    "        value=\"-2 to -1 Std Dev\",\n",
    "        label=labels[1],\n",
    "        symbol=symbol2,\n",
    "    ),\n",
    "    UniqueValueInfo(\n",
    "        value=\"-1 to 0 Std Dev\",\n",
    "        label=labels[2],\n",
    "        symbol=symbol3,\n",
    "    ),\n",
    "    UniqueValueInfo(\n",
    "        value=\"0 to 1 Std Dev\",\n",
    "        label=labels[3],\n",
    "        symbol=symbol4,\n",
    "    ),\n",
    "    UniqueValueInfo(\n",
    "        value=\"1 to 2 Std Dev\",\n",
    "        label=labels[4],\n",
    "        symbol=symbol5,\n",
    "    ),\n",
    "    UniqueValueInfo(\n",
    "        value=\"> 2 Std Dev\",\n",
    "        label=labels[5],\n",
    "        symbol=symbol6,\n",
    "    )\n",
    "]\n",
    "\n",
    "uvr = UniqueValueRenderer(\n",
    "    type=\"uniqueValue\",\n",
    "    field1=\"Total_Vacant_Change_Std\",\n",
    "    uniqueValueInfos=unique_value_infos,\n",
    ")\n",
    "\n",
    "#Labeling info\n",
    "\n",
    "labeling_info = [\n",
    "      {\n",
    "        \"labelExpression\": \"[TRACTCE],[BLKGRPCE]\",\n",
    "        \"labelPlacement\": \"esriServerPolygonPlacementAlwaysHorizontal\",\n",
    "        \"repeatLabel\": True,\n",
    "        \"symbol\": {\n",
    "          \"type\": \"esriTS\",\n",
    "          \"color\": [\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            255\n",
    "          ],\n",
    "          \"font\": {\n",
    "            \"family\": \"Arial\",\n",
    "            \"size\": 12\n",
    "          },\n",
    "          \"horizontalAlignment\": \"center\",\n",
    "          \"kerning\": True,\n",
    "        },\n",
    "      }\n",
    "]\n",
    "\n",
    "options_dict = {\n",
    "    \"showLabels\" : True,\n",
    "    \"layerDefinition\" : {\n",
    "        \"drawingInfo\" : {\n",
    "            # \"labelingInfo\" : labeling_info,\n",
    "            \"renderer\" : uvr.dict(),\n",
    "        },\n",
    "        \"title\" : \"Puerto Rico Vacant Housing Change\",\n",
    "    },\n",
    "    \"opacity\" : 0.5,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county = \"Cabo Rojo\"\n",
    "\n",
    "county_filter = blck_grp_merged[blck_grp_merged[\"COUNTY\"] == f\"{county} Municipio\"]\n",
    "\n",
    "m3 = Map(f\"{county}, PR\")\n",
    "m3.content.add(county_filter, options = options_dict)\n",
    "m3.content.add(lecz, options={\"opacity\": 0.5})\n",
    "m3\n",
    "# update the WebMap in Notebooks\n",
    "m3.content.update_layer(\n",
    "    index = 1, \n",
    "    options= {\n",
    "        \"title\": \"LECZ\",\n",
    "        \"layerDefinition\" : layer_def\n",
    "    }\n",
    ")\n",
    "m3.content.update_layer(index = 0, options= {\"title\": \"Puerto Rico Vacant Housing Change\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3.legend.enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
